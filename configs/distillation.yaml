# Knowledge distillation: DeiT-Small teacher → MobileViT-Small student
#
# Distills encoder feature representations relevant for music note recognition.
# The frozen teacher provides two training signals:
#   1. Encoder feature alignment (MSE, weight beta)
#   2. Soft output distributions (KL divergence, weight gamma)
#
# Usage: python -m src.train --config configs/distillation.yaml

model:
  type: "Distillation"

  teacher:
    # Best Phase-1 backbone checkpoint (update path after sweep completes)
    checkpoint: "networks/checkpoints/deit_small/stage_1/best_checkpoint.pt"

  student:
    params:
      vision_model_name: "apple/mobilevit-small"
      d_model: 512
      n_heads: 8
      n_decoder_layers: 6
      d_ff: 2048
      max_seq_len: 2048
      dropout: 0.1

  distillation:
    alpha: 0.3        # hard-label CE weight
    beta: 0.5         # encoder feature MSE weight (emphasised)
    gamma: 0.2        # logit KL divergence weight
    temperature: 4.0  # softmax temperature for logit KD

data:
  dataset_id: "guangyangmusic/PDMX-Synth"
  tokenizer_id: "guangyangmusic/legato"
  img_height: 224
  num_workers: 1
  pin_memory: true

training:
  batch_size: 8
  gradient_accumulation_steps: 4
  epochs: 10
  optimizer:
    type: "AdamW"
    learning_rate: 0.0003
    weight_decay: 0.01
    betas: [0.9, 0.99]
    eps: 0.000001
  scheduler:
    type: "LinearWarmup"
    warmup_ratio: 0.03
  early_stop_patience: 6
  grad_clip_norm: 1.0
  checkpoint_dir: "networks/checkpoints/distill_deit_to_mobilevit"

logging:
  use_wandb: true
  verbose: false
  wandb:
    project: "music-recognition"
    run_name: "distill-deit-to-mobilevit"
    tags: ["distillation", "mobilevit-small", "deit-small-teacher", "omr"]
    notes: "Knowledge distillation: DeiT-Small (59M) → MobileViT-Small (42M), feature-focused"

hardware:
  device: "auto"
  mixed_precision: true
