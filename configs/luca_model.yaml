# Configuration for Music-TrOCR model training
# Usage: python train.py --config configs/luca_model.yaml

# Model configuration
model:
  type: "MusicTrOCR"
  params:
    vision_model_name: "facebook/convnext-tiny-224"
    
    # Transformer decoder parameters
    d_model: 512              # Hidden dimension
    n_heads: 8               # Number of attention heads
    n_decoder_layers: 6      # Number of decoder layers
    d_ff: 2048              # Feed-forward dimension
    max_seq_len: 2048       # Maximum sequence length (matches tokenizer model_max_length)
    dropout: 0.1            # Dropout rate

# Data configuration
data:
  dataset_id: "guangyangmusic/PDMX-Synth"
  tokenizer_id: "guangyangmusic/legato"
  img_height: 224

  # Data loading
  num_workers: 1
  pin_memory: true

# Training configuration
training:
  batch_size: 8
  gradient_accumulation_steps: 4  # effective batch size = 8 * 4 = 32
  epochs: 10

  # Optimizer settings (following LEGATO paper)
  optimizer:
    type: "AdamW"
    learning_rate: 0.0003
    weight_decay: 0.01
    betas: [0.9, 0.99]
    eps: 0.000001

  # Learning rate scheduler (linear warmup + linear decay)
  scheduler:
    type: "LinearWarmup"
    warmup_ratio: 0.03
  
  # Early stopping
  early_stop_patience: 6
  
  # Gradient clipping
  grad_clip_norm: 1.0
  
  # Checkpointing
  checkpoint_dir: "networks/checkpoints/luca_model"

# Logging configuration
logging:
  use_wandb: true
  verbose: false
  wandb:
    project: "music-recognition"
    run_name: "music-trocr-convnext-tiny"
    tags: ["music-trocr", "convnext", "transformer", "omr"]
    notes: "Music-TrOCR with ConvNeXt-Tiny backbone and transformer decoder"

# Hardware configuration
hardware:
  device: "auto"  # auto, cpu, cuda
  mixed_precision: true  # Use automatic mixed precision (AMP)