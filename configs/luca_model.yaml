# Configuration for Music-TrOCR model training
# Usage: python train.py --config configs/luca_model.yaml

# Model configuration
model:
  type: "MusicTrOCR"
  params:
    vision_model_name: "facebook/convnext-tiny-224"
    
    # Transformer decoder parameters
    d_model: 512              # Hidden dimension
    n_heads: 8               # Number of attention heads
    n_decoder_layers: 6      # Number of decoder layers
    d_ff: 2048              # Feed-forward dimension
    max_seq_len: 512        # Maximum sequence length
    dropout: 0.1            # Dropout rate

# Data configuration
data:
  dataset_path: 
    - "data/primus/package_aa"
    - "data/primus/package_ab"
  vocabulary_path: "data/semantic_labels.txt"
  split_ratio: [0.8, 0.15, 0.05]  # train, val, test
  num_workers: 4
  pin_memory: true

# Training configuration
training:
  batch_size: 8
  epochs: 200
  
  # Optimizer settings
  optimizer:
    type: "Adam"
    learning_rate: 0.0001
    weight_decay: 0.00001
    betas: [0.9, 0.999]
  
  # Learning rate scheduler
  scheduler:
    type: "ReduceLROnPlateau"
    mode: "min"
    factor: 0.5
    patience: 5
    threshold: 0.0001
    threshold_mode: "rel"
    cooldown: 2
    eps: 0.00000001
  
  # Early stopping
  early_stop_patience: 15
  
  # Gradient clipping
  grad_clip_norm: 1.0
  
  # Checkpointing
  checkpoint_dir: "networks/checkpoints/luca_model"

# Logging configuration
logging:
  use_wandb: true
  wandb:
    project: "music-recognition"
    run_name: "music-trocr-convnext-tiny"
    tags: ["music-trocr", "convnext", "transformer", "omr"]
    notes: "Music-TrOCR with ConvNeXt-Tiny backbone and transformer decoder"

# Hardware configuration
hardware:
  device: "auto"  # auto, cpu, cuda
  mixed_precision: false  # Use automatic mixed precision (AMP)