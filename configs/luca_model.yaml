# Configuration for Music-TrOCR model training
# Usage: python train.py --config configs/luca_model.yaml

# Model configuration
model:
  type: "MusicTrOCR"
  params:
    vision_model_name: "facebook/convnext-tiny-224"
    
    # Transformer decoder parameters
    d_model: 512              # Hidden dimension
    n_heads: 8               # Number of attention heads
    n_decoder_layers: 6      # Number of decoder layers
    d_ff: 2048              # Feed-forward dimension
    max_seq_len: 512        # Maximum sequence length
    dropout: 0.1            # Dropout rate

# Data configuration
data:
  # List of datasets with their formats
  datasets:
    #- path: "data/datasets/primus"
    #  format: "primus"
    #  full_page: false
    - path: "data/datasets/smt_datasets/camera-grandstaff"
      format: "bekern"
      full_page: true
  
  # Vocabulary configuration
  primus_vocabulary_path: "data/semantic_labels.txt"  # For primus format datasets
  bekern_vocabulary_path: "data/FP_GrandStaff_BeKernw2i.npy"  # For bekern format datasets
  mapping_file_path: "data/primus_to_bekern_mapping.json"  # Conversion mapping file
  
  # Data processing
  num_workers: 4
  pin_memory: true
  use_unified_format: true  # If true, convert all to bekern format for consistency

# Training configuration
training:
  batch_size: 64
  epochs: 200
  
  # Optimizer settings
  optimizer:
    type: "Adam"
    learning_rate: 0.0001
    weight_decay: 0.00001
    betas: [0.9, 0.999]
  
  # Learning rate scheduler
  scheduler:
    type: "ReduceLROnPlateau"
    mode: "min"
    factor: 0.5
    patience: 5
    threshold: 0.0001
    threshold_mode: "rel"
    cooldown: 2
    eps: 0.00000001
  
  # Early stopping
  early_stop_patience: 15
  
  # Gradient clipping
  grad_clip_norm: 1.0
  
  # Checkpointing
  checkpoint_dir: "networks/checkpoints/luca_model"

# Logging configuration
logging:
  use_wandb: true
  verbose: false
  wandb:
    project: "music-recognition"
    run_name: "music-trocr-convnext-tiny"
    tags: ["music-trocr", "convnext", "transformer", "omr"]
    notes: "Music-TrOCR with ConvNeXt-Tiny backbone and transformer decoder"

# Hardware configuration
hardware:
  device: "auto"  # auto, cpu, cuda
  mixed_precision: false  # Use automatic mixed precision (AMP)