{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "demo-header",
   "metadata": {},
   "source": [
    "# MusicTrOCR (Luca Model) Demonstration\n",
    "\n",
    "This notebook demonstrates the capabilities of the MusicTrOCR model for Optical Music Recognition (OMR). The model converts sheet music images into BeKern notation and visualizes the results.\n",
    "\n",
    "## Architecture Overview\n",
    "- **Vision Encoder**: ConvNeXt-Tiny pre-trained backbone\n",
    "- **Decoder**: Transformer decoder with cross-attention\n",
    "- **Output**: BeKern notation (symbolic music representation)\n",
    "- **Visualization**: Verovio rendering engine for score display\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "Set the paths for the demo image and trained model checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo configuration\n",
    "img_name = \"demos/demo.png\"  # Input sheet music image\n",
    "ckpt_path = \"networks/checkpoints/luca_model/best_model.pth\"  # Trained model checkpoint\n",
    "\n",
    "# Optional: Override paths if needed\n",
    "# img_name = \"path/to/your/demo/image.png\"\n",
    "# ckpt_path = \"path/to/your/checkpoint.pth\"\n",
    "\n",
    "print(f\"Demo image: {img_name}\")\n",
    "print(f\"Model checkpoint: {ckpt_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-header",
   "metadata": {},
   "source": [
    "## 2. Dependencies & Imports\n",
    "Load required libraries and utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import demo utilities\n",
    "from utils import (\n",
    "    load_model_and_vocab,\n",
    "    preprocess_image,\n",
    "    run_inference,\n",
    "    decode_bekern_prediction,\n",
    "    bekern_to_kern,\n",
    "    render_music_score,\n",
    "    visualize_results,\n",
    "    demo_pipeline\n",
    ")\n",
    "\n",
    "print(\"Dependencies loaded successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device available: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-loading-header",
   "metadata": {},
   "source": [
    "## 3. Model Loading\n",
    "Load the trained MusicTrOCR model and BeKern vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-loading-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and vocabulary\n",
    "print(\"Loading MusicTrOCR model...\")\n",
    "\n",
    "try:\n",
    "    model, vocab_dict, id_to_token = load_model_and_vocab(\n",
    "        ckpt_path=ckpt_path,\n",
    "        vocab_path=\"data/FP_GrandStaff_BeKernw2i.npy\"\n",
    "    )\n",
    "    \n",
    "    print(\"\\n✅ Model loaded successfully!\")\n",
    "    print(f\"Model parameters: {model.count_parameters():,}\")\n",
    "    print(f\"Vocabulary size: {len(vocab_dict)}\")\n",
    "    \n",
    "    # Display some vocabulary examples\n",
    "    print(\"\\nSample vocabulary tokens:\")\n",
    "    sample_tokens = list(vocab_dict.keys())[:10]\n",
    "    for token in sample_tokens:\n",
    "        print(f\"  {token} -> {vocab_dict[token]}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading model: {e}\")\n",
    "    print(\"Please check that the checkpoint path exists and is valid.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "image-preprocessing-header",
   "metadata": {},
   "source": [
    "## 4. Image Preprocessing\n",
    "Load and preprocess the demo sheet music image for model input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "image-preprocessing-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if demo image exists\n",
    "if not os.path.exists(img_name):\n",
    "    print(f\"❌ Demo image not found: {img_name}\")\n",
    "    print(\"Please place a sheet music image at the specified path.\")\n",
    "    print(\"You can use any sheet music image (PNG, JPG, etc.)\")\n",
    "else:\n",
    "    # Load and display original image\n",
    "    print(f\"Loading demo image: {img_name}\")\n",
    "    \n",
    "    # Display original image\n",
    "    original_img = Image.open(img_name)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(original_img, cmap='gray')\n",
    "    plt.title(f\"Original Input Image: {img_name}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Preprocess for model\n",
    "    try:\n",
    "        image_tensor = preprocess_image(img_name, target_height=128)\n",
    "        print(\"\\n✅ Image preprocessed successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error preprocessing image: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inference-header",
   "metadata": {},
   "source": [
    "## 5. Model Inference\n",
    "Run the MusicTrOCR model to generate BeKern notation predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inference-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference if model and image are loaded\n",
    "if 'model' in locals() and 'image_tensor' in locals():\n",
    "    print(\"Running MusicTrOCR inference...\")\n",
    "    \n",
    "    try:\n",
    "        # Generate predictions\n",
    "        predictions = run_inference(model, image_tensor, max_length=512)\n",
    "        \n",
    "        print(f\"\\n✅ Inference completed!\")\n",
    "        print(f\"Generated sequence shape: {predictions.shape}\")\n",
    "        \n",
    "        # Display raw token predictions (first 20 tokens)\n",
    "        raw_tokens = predictions.squeeze().tolist()[:20]\n",
    "        print(f\"\\nFirst 20 predicted tokens: {raw_tokens}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during inference: {e}\")\nelse:\n",
    "    print(\"❌ Cannot run inference: model or image not loaded properly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decoding-header",
   "metadata": {},
   "source": [
    "## 6. Prediction Decoding\n",
    "Convert model token predictions to readable BeKern notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decoding-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode predictions if available\n",
    "if 'predictions' in locals() and 'id_to_token' in locals():\n",
    "    print(\"Decoding token predictions to BeKern notation...\")\n",
    "    \n",
    "    try:\n",
    "        # Decode tokens to BeKern string\n",
    "        bekern_str = decode_bekern_prediction(predictions, id_to_token, model)\n",
    "        \n",
    "        print(\"\\n✅ Decoding completed!\")\n",
    "        print(f\"BeKern string length: {len(bekern_str)} characters\")\n",
    "        \n",
    "        # Display BeKern notation preview\n",
    "        print(\"\\n--- BeKern Notation Preview ---\")\n",
    "        preview_length = min(300, len(bekern_str))\n",
    "        print(bekern_str[:preview_length])\n",
    "        if len(bekern_str) > preview_length:\n",
    "            print(\"... (truncated)\")\n",
    "            \n",
    "        # Token statistics\n",
    "        tokens = bekern_str.split()\n",
    "        print(f\"\\nToken count: {len(tokens)}\")\n",
    "        print(f\"Unique tokens: {len(set(tokens))}\")\n",
    "        \n",
    "        # Most frequent tokens\n",
    "        from collections import Counter\n",
    "        token_counts = Counter(tokens)\n",
    "        print(\"\\nMost frequent tokens:\")\n",
    "        for token, count in token_counts.most_common(10):\n",
    "            print(f\"  '{token}': {count}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during decoding: {e}\")\nelse:\n",
    "    print(\"❌ Cannot decode: predictions not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conversion-header",
   "metadata": {},
   "source": [
    "## 7. BeKern to Kern Conversion\n",
    "Convert BeKern format to standard Kern format for music rendering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conversion-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert BeKern to Kern format\n",
    "if 'bekern_str' in locals():\n",
    "    print(\"Converting BeKern to Kern format for rendering...\")\n",
    "    \n",
    "    try:\n",
    "        # Convert format\n",
    "        kern_str = bekern_to_kern(bekern_str)\n",
    "        \n",
    "        print(\"\\n✅ Format conversion completed!\")\n",
    "        print(f\"Kern string length: {len(kern_str)} characters\")\n",
    "        \n",
    "        # Display Kern format preview\n",
    "        print(\"\\n--- Kern Format Preview ---\")\n",
    "        kern_lines = kern_str.split('\\n')[:10]  # First 10 lines\n",
    "        for i, line in enumerate(kern_lines):\n",
    "            print(f\"{i+1:2d}: {line}\")\n",
    "        \n",
    "        if len(kern_str.split('\\n')) > 10:\n",
    "            print(\"... (more lines)\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during format conversion: {e}\")\nelse:\n",
    "    print(\"❌ Cannot convert format: BeKern string not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization-header",
   "metadata": {},
   "source": [
    "## 8. Music Score Rendering\n",
    "Render the Kern notation as a visual music score using Verovio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualization-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render music score\n",
    "if 'kern_str' in locals():\n",
    "    print(\"Rendering music score from Kern notation...\")\n",
    "    \n",
    "    try:\n",
    "        # Render score to image\n",
    "        rendered_score = render_music_score(kern_str, \"demos/output_score.png\")\n",
    "        \n",
    "        if rendered_score is not None:\n",
    "            print(\"\\n✅ Music score rendered successfully!\")\n",
    "            print(f\"Rendered image shape: {rendered_score.shape}\")\n",
    "            \n",
    "            # Display rendered score\n",
    "            plt.figure(figsize=(14, 8))\n",
    "            plt.imshow(rendered_score)\n",
    "            plt.title(\"Rendered Music Score from Predictions\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"⚠️ Music score rendering failed (Verovio may not be available)\")\n",
    "            print(\"The BeKern and Kern text outputs above show the symbolic representation.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during rendering: {e}\")\nelse:\n",
    "    print(\"❌ Cannot render: Kern notation not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results-header",
   "metadata": {},
   "source": [
    "## 9. Results Comparison\n",
    "Display side-by-side comparison of input and predicted output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "results-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display final results\n",
    "if 'bekern_str' in locals() and os.path.exists(img_name):\n",
    "    print(\"Displaying final results...\")\n",
    "    \n",
    "    # Get rendered score if available\n",
    "    score_image = rendered_score if 'rendered_score' in locals() else None\n",
    "    \n",
    "    # Show comparison\n",
    "    visualize_results(img_name, score_image, bekern_str)\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\n=== DEMO SUMMARY ===\")\n",
    "    print(f\"Input image: {img_name}\")\n",
    "    print(f\"Model checkpoint: {ckpt_path}\")\n",
    "    print(f\"BeKern tokens generated: {len(bekern_str.split())}\")\n",
    "    print(f\"Kern notation lines: {len(kern_str.split(chr(10))) if 'kern_str' in locals() else 'N/A'}\")\n",
    "    print(f\"Score visualization: {'✅ Success' if score_image is not None else '❌ Failed'}\")\n",
    "    \nelse:\n",
    "    print(\"❌ Cannot display results: required data not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-pipeline-header",
   "metadata": {},
   "source": [
    "## 10. Complete Pipeline (Alternative)\n",
    "Run the entire demo pipeline in one step using the utility function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-pipeline-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Run complete pipeline at once\n",
    "# Uncomment and run this cell to execute the entire demo in one step\n",
    "\n",
    "# results = demo_pipeline(\n",
    "#     img_path=img_name,\n",
    "#     ckpt_path=ckpt_path,\n",
    "#     vocab_path=\"data/FP_GrandStaff_BeKernw2i.npy\"\n",
    "# )\n",
    "\n",
    "print(\"Complete pipeline function available but commented out.\")\n",
    "print(\"Uncomment the lines above to run the entire demo in one step.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This demo showcased the MusicTrOCR (Luca Model) capabilities for Optical Music Recognition:\n",
    "\n",
    "1. **Image Processing**: Converted sheet music image to model input format\n",
    "2. **Neural Inference**: Used transformer architecture to predict music notation\n",
    "3. **Sequence Decoding**: Converted model tokens to BeKern symbolic notation\n",
    "4. **Format Conversion**: Transformed BeKern to standard Kern format\n",
    "5. **Visual Rendering**: Generated visual music score from symbolic representation\n",
    "\n",
    "### Model Architecture\n",
    "- **Vision Encoder**: ConvNeXt-Tiny pre-trained backbone\n",
    "- **Text Decoder**: 6-layer transformer with cross-attention\n",
    "- **Vocabulary**: BeKern format with ~300 music symbols\n",
    "- **Generation**: Autoregressive sequence prediction\n",
    "\n",
    "### Next Steps\n",
    "- Try different sheet music images\n",
    "- Experiment with generation parameters (temperature, max_length)\n",
    "- Compare with other OMR approaches\n",
    "- Analyze prediction confidence and error patterns\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}